{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8849947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools  # This will allow us to load tools we need\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "#from langchain.llms import OpenAI\n",
    "\n",
    "## We can also use a model from HuggingFaceHub if we wish to go open-source!\n",
    "\n",
    "cachee_dir=\"/Users/giannitallarita/Downloads/titanic\"\n",
    "\n",
    "model_id = \"EleutherAI/gpt-j-6b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id , max_length=512, local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model,tokenizer=tokenizer, max_new_tokens=512, device_map='auto'\n",
    ")\n",
    "jekyll_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "csvd=CSVLoader(file_path='/Users/giannitallarita/Downloads/titanic/train.csv', csv_args={\n",
    "    'delimiter': ',',\n",
    "    'quotechar': '\"',\n",
    "    'fieldnames': ['PassengerId', 'Survived', 'Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde96a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_size = 500\n",
    "#chunk_overlap = 0\n",
    "\n",
    "data = csvd.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3466cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "#args = parse_arguments()\n",
    "\n",
    "    # activate/deactivate the streaming StdOut callback for LLMs\n",
    "#loader = TextLoader(\"../../state_of_the_union.txt\")\n",
    "#documents = loader.load()\n",
    "#text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "#texts = text_splitter.split_documents(data)\n",
    "texts=data\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "#retriever = db.as_retriever(search_kwargs={\"k\": target_source_chunks})\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=jekyll_llm, chain_type=\"stuff\", retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many columns are there?\"\n",
    "qa.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('gpus')",
   "language": "python",
   "name": "python31011jvsc74a57bd05cc08c2914391f4ad7641ac53d875a20023b6b1c6d27c120f712dd41935f8d44"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
