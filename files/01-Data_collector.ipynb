{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imports ####\n",
    "#################\n",
    "\n",
    "### basics\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "\n",
    "\n",
    "### yahoo finance\n",
    "import yfinance as yf\n",
    "\n",
    "### pandas\n",
    "import pandas as pd\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "\n",
    "### data optimization library\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage,risk_matrix\n",
    "from pypfopt import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions ####\n",
    "###################\n",
    "def data_from_names(stocks_names):\n",
    "    '''\n",
    "    Downloads daily data of 10 years history of stocks.\n",
    "\n",
    "    Arguments:\n",
    "    stock_names: (list) stock names as named by yahoo finance.\n",
    "    '''\n",
    "    dataset = pd.DataFrame()\n",
    "    for s in stocks_names:\n",
    "        value = yf.Ticker(s).history(period = \"10y\").Close\n",
    "        dat = pd.DataFrame({\"{}\".format(s): value})\n",
    "        dataset = pd.concat([dataset,dat],axis = 1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_train_test(dataset,first,end):\n",
    "    '''\n",
    "    Divide data set in train and test. This will be useful to train our stocks along with our previous Risk tolerance, and then the test set will be used to perform backtests. \n",
    "    \n",
    "    Arguments:\n",
    "    dataset: (Dataframe) index:(Timestamp), cols:(float) stock price values\n",
    "    first: ((list) shape=(3)) [(int) year,(int) month,(int) day]\n",
    "    end:   ((list) shape=(3)) [(int) year,(int) month,(int) day]\n",
    "    '''\n",
    "\n",
    "    first = [str(f) for f in first]\n",
    "    end = [str(e) for e in end]\n",
    "\n",
    "    y_1,m_1,d_1 = first\n",
    "    y_2,m_2,d_2 = end\n",
    "    print( y_1,m_1,d_1)\n",
    "\n",
    "    if len(m_1) == 1:\n",
    "        m_1 = \"0\"+m_1\n",
    "    if len(m_2) == 1:\n",
    "        m_2 = \"0\"+m_2\n",
    "    if len(d_1) == 1:\n",
    "        d_1 = \"0\"+d_1\n",
    "    if len(d_2) == 1:\n",
    "        d_2 = \"0\"+d_2\n",
    "\n",
    "\n",
    "    dates_times = dataset.index\n",
    "    dates = [fulldate.strftime('%Y-%m-%d') for fulldate in dates_times]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        idx_1 =  dates.index(f\"{y_1}-{m_1}-{d_1}\")\n",
    "    except:\n",
    "        print(\"This date for Begin doesnt exist, try another\")\n",
    "\n",
    "    try:\n",
    "        idx_2 =  dates.index(f\"{y_2}-{m_2}-{d_2}\")\n",
    "    except:\n",
    "        print(\"This date for END doesnt exist, try another\")\n",
    "    \n",
    "    return dataset[idx_1:idx_2],dataset[idx_2:]\n",
    "\n",
    "\n",
    "def data_cleaner(data):\n",
    "  '''\n",
    "    Divide data set in train and test. This will be useful to train our stocks along with our previous Risk tolerance, and then the test set will be used to perform backtests. \n",
    "    \n",
    "    Arguments:\n",
    "    dataset: (Dataframe) index:(Timestamp), cols:(float) stock price values\n",
    "    first: ((list) shape=(3)) [(int) year,(int) month,(int) day]\n",
    "    end:   ((list) shape=(3)) [(int) year,(int) month,(int) day]\n",
    "    '''\n",
    "    #Checking for any null values and removing the null values'''\n",
    "    if data.isnull().values.any():\n",
    "        print(\"There are NULLS in dataframe\")\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        print(\"Remove columns with less than 30 percent of data\")\n",
    "        missing_fractions = data.isnull().mean().sort_values(ascending=False)\n",
    "        missing_fractions.head(10)\n",
    "        drop_list = sorted(list(missing_fractions[missing_fractions > 0.3].index))\n",
    "        data.drop(labels=drop_list, axis=1, inplace=True)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read n Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarto las columnas que les faltan m√°s del 30% de los datos\n"
     ]
    }
   ],
   "source": [
    "data = data_from_names([\"ITOT\",\"IVV\",\"QQQ\",\"VTI\",\"IJR\",\"VPL\",\"VWO\",\"SUSA\",\"HYEM\",\"MGV\"])\n",
    "data_cleaner(data)\n",
    "data.to_csv(\"data/assets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roboadvisor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
